{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#project-layout","title":"Project layout","text":"<p>Created by Adrian Fisher</p> <pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md             # The documentation homepage.\n    01_introduction.md   # Introduction to Docker\n    02_containers.md     # Introduction to containers\n    03_installation.md   # Installing Docker and running a container\n    04_docker-ssh.md     # Installing SSH inside a container\n    05_basic-commands.md # Learning basic Docker commands\n    06_examples.md       # Giving examples of Docker usage\n</code></pre>"},{"location":"01_introduction/","title":"1: Introduction","text":"<p>Docker is a tool which allows users to build, share, package, verify, and run applications in isolated environments called containers while avoiding the tedium of environment confirguration and management.</p> <p>It's not uncommon when programming collaboratively that something that might work well on one user's environment will run into issues when another user tries to run the same steps. Docker ensures that applications and their dependencies are bundled together in a portable format, side-stepping the classic \"well, it works on my machine\" issue which can be otherwise difficult to solve. Whether developing from your personal laptop or deploying to production servers, Docker helps to ensure that the environment stays consistent.</p> <p>Containers are lightweight and fast, built to share the host's operating system's kernal rather than running full virtual machines. This makes them efficiently capable of isolating processses, testing software in clean environments, or managing complex multi-service applications without polluting your local system.</p> <p>In this lesson, we'll explore:</p> <ul> <li>What containers are and how they differ from virtual machines.</li> <li>How to install Docker and run your first container.</li> <li>How to install SSH inside a container, and why you might choose to do so.</li> <li>How to use basic Docker commands to build, inspect, and manage your containers.</li> <li>Practical examples to illustrate how Docker can simplify both development and deployment workflows.</li> </ul> <p>By the end of this lesson, you should have a working understanding of how to use Docker to create reliable and reproducible environments for your projects. </p> <p>Let's continue to section 2 to begin learning about container images and containers.</p>"},{"location":"02_containers/","title":"2: Containers and Images","text":"<p>When working with Docker, two core concepts that you'll encounter are container images and containers. Understanding them both and the distinctions between them is key to the effective use of Docker.</p>"},{"location":"02_containers/#container-images","title":"Container Images","text":"<p>A container image can be likened to a packaged blueprint of a container, including everything that a program requires to run such as the code of the application itself, the required system libraries and dependencies, the configuration files and environment settings, etc.</p> <p>Container images are static and read-only - you can think of them as snapshots or templates. Once built, they can be stored, shared, and reused on any system that supports Docker. </p> <p>Docker images are versioned and portable, allowing you to move seamlessly between development, testing, and production environments. </p>"},{"location":"02_containers/#containers","title":"Containers","text":"<p>Docker describes containers as \"a standard unit of software\" which packages all code and its dependencies. It can also be thought of as a running instance of a container image. When Docker starts a container, it creates a writable layer \"on top\" of the read-only image, before allowing the application to run in an isolated environment with its own file system, network interfaces, and process space. You can run multiple containers from the same image at the same time while allowing each container to act as an independent unit. </p> <p>For example, it might be useful to use the same database image to run one container for development, another for automated tests, and a third in production. Despite all coming from the same image, each container is able to store its own data and settings.</p> <p>This separation between images (the blueprints) and containers (the running instances) allows Docker to quickly set up new environments, efficiently reuse resources, and ensure consistency across machines and stages of development.</p>"},{"location":"02_containers/#containers-vs-virtual-machines","title":"Containers vs. Virtual Machines","text":"<p>While containers and virtual machines (VMs) might seem similar at a glance (both allow you to run isolated environments), the way that they achieve their isolation and their performance characteristics are significantly different. </p> <p>A virtual machine emulates an entire computer, including: * Its own guest operating system. * Virtual hardware, such as CPU, memory, disk, and network interfaces. Each VM runs on top of a hypervisor, such as VirtualBox or VMware, which sits between the physical hardware and the virtual machine.</p> <p>As mentioned before, a container shares the host's operating system kernal, simply isolating the file system, processes, and network. To summarize:</p> Feature Virtual Machine Container OS: Full OS per VM Shares host OS kernel Startup Time: Minutes Seconds Resource Usage: Heavy (GBs of disk space, RAM intensive) Light (MBs to low GBs) Isolation: Hardware-level Process-level <p>Let's continue on to section 3 to install Docker and start working with containers.</p>"},{"location":"03_installation/","title":"3: Installing Docker","text":"<p>Docker Desktop is the primary application for managing containers on your local machine. It provides a user-friendly GUI, integrates with your system's Command-Line Interface (CLI) tools, and includes everything necessary to build and share containerized apps.  While there are several paid options for using Docker, it is completely free for personal use. If you are planning on using Docker for advanced and professional use, click here to see the pricing options. Otherwise, you can begin your download by following this link to the official site. Docker has download options for Mac (Apple Silicon or Intel Chip), Windows (AMD64 or ARM64), and Linux. You may be prompted to enable WSL2 (on Windows), grant system permissions (on macOS), or install supporting packages (on Linux). The installer will walk you through these steps automatically. This installation will also require you to restart your machine to be completed, so be sure to save important work before doing this installation.</p> <p>After completing your installation, open a terminal (or command prompt for Windows) and run:</p> <pre><code>docker run hello-world\n</code></pre> <p>This will download the <code>hello-world</code> image if it's not already present before running a small container which prints a confirmation message if everything is working correctly. Running this helps to verify that your Docker Engine is running correctly and that Docker can fetch and execute containers from Docker Hub. If this works, your installation is complete and functional. If it fails to run, make sure that Docker Desktop is open and running. On some systems, you may need to enable virtualization in your BIOS or allow Docker through your firewall.</p> <p>Let's continue to section 4 to learn how to set up an SSH inside a container.</p>"},{"location":"04_docker-ssh/","title":"4: Installing SSH Inside a Container","text":""},{"location":"04_docker-ssh/#why-install-ssh-in-a-container","title":"Why Install SSH in a Container?","text":"<p>In most cases, SSH is not necessary in containers. Docker is designed to run a single applciation per container, and you typically interact with it using <code>docker exec</code>, <code>docker attach</code> or Docker Compose. Adding SSH can increase the image size, introduce complexity, and create potential security concerns.</p> <p>However, there are situations in which installing SSH makes sense: * Legacy Systems: You're containerizing an existing system that expects SSH access. * Remote Debugging: You want to attach to containers from another machine using familiar SSH tools. * Custom VM-like Containers: You're using containers in place of VMs and want them to behave similarly.</p>"},{"location":"04_docker-ssh/#step-by-step-installing-ssh-in-a-container","title":"Step-by-step: Installing SSH in a Container","text":"<p>While using an Ubuntu terminal, we'll create an Ubuntu-based container, install OpenSSH Server, and configure it to accept connections. </p> <p>Note: Angled brackets in this lesson denote user-specific content - be sure to delete them and replace them to your preference. For more information on using SSH, visit our HSF training page, here.</p>"},{"location":"04_docker-ssh/#1-create-a-project-folder-optional-but-recommended","title":"1. Create a project folder (optional but recommended)","text":"<pre><code>mkdir &lt;your-ssh-container&gt;\ncd &lt;your-ssh-container&gt;\n</code></pre>"},{"location":"04_docker-ssh/#2-create-a-file-named-dockerfile-no-file-extension-using-the-ubuntu-terminal-wsl","title":"2. Create a file named <code>Dockerfile</code> (no file extension) using the Ubuntu terminal (WSL)","text":"<pre><code>touch Dockerfile\n</code></pre>"},{"location":"04_docker-ssh/#3-open-the-dockerfile-in-a-text-editor","title":"3. Open the Dockerfile in a text editor:","text":"<ul> <li>If you're using VS Code:</li> </ul> <pre><code>code Dockerfile\n</code></pre> <ul> <li>Or use nano/vim:</li> </ul> <pre><code>nano Dockerfile\n</code></pre>"},{"location":"04_docker-ssh/#4-paste-the-dockerfile-content","title":"4. Paste the Dockerfile content:","text":"<pre><code>FROM ubuntu:22.04\n\n# Install SSH Server\nRUN apt-get update &amp;&amp; apt-get install -y openssh-server\n\n# Create SSH directory and set password for root - replace part in angle brackets\nRUN mkdir /var/run/sshd &amp;&amp; echo 'root:&lt;your-new-password&gt;' | chpasswd\n\n# Allow root login (not recommended for production)\nRUN sed -i 's/#PermitRootLogin prohibit-password/PermitRootLogin yes/' /etc/ssh/sshd_config\n\n# Expose port 22 and start SSH\nEXPOSE 22\nCMD [\"/usr/sbin/sshd\", \"-D\"]\n</code></pre>"},{"location":"04_docker-ssh/#5-save-and-close-the-file","title":"5. Save and close the file.","text":""},{"location":"04_docker-ssh/#6-build-the-image","title":"6. Build the Image","text":"<p>In the same directory as your <code>Dockerfile</code>, run:</p> <pre><code>docker build -t &lt;your-ssh-container&gt; .\n</code></pre> <ul> <li><code>-t</code> tags your image with a human-readable name.</li> <li><code>.</code> tells Docker to look in the current directory for the Dockerfile. This step may take a couple of minutes for your machine to complete.</li> </ul>"},{"location":"04_docker-ssh/#7-run-a-container-from-the-image","title":"7. Run a Container from the Image","text":"<pre><code>docker run -d -p 2222:22 --name ssh-container &lt;your-ssh-container&gt;\n</code></pre> <ul> <li>This maps port <code>22</code> inside the container to port <code>2222</code> on your machine. You should now be able to SSH in using:</li> </ul> <pre><code>ssh root@localhost -p 2222\n</code></pre> <p>This will prompt you to enter the password which was set in step 4 (<code>RUN mkdir /var/run/sshd &amp;&amp; echo 'root:&lt;your-new-password&gt;' | chpasswd</code>). </p> <p>Let's continue now to section 5 to learn some basic commands in Docker.</p>"},{"location":"05_basic-commands/","title":"5: Basic Docker Commands","text":"<p>Once Docker is installed, you'll primarily use the <code>docker</code> CLI to interact with images and containers. Here's some of the essential commands that cover the full lifecycle: build, run, inspect, and manage.</p>"},{"location":"05_basic-commands/#building-a-docker-image","title":"Building a Docker Image","text":"<p>To create a container, you first need an image. If you have a <code>Dockerfile</code>, you can build an image from it:</p> <pre><code>docker build -t &lt;your-image-name&gt; .\n</code></pre> <p>As mentioned in the previous section, the command <code>-t</code> tags your image with a human-readable name, while <code>.</code> specifies the current directory as the build context.</p> <p>Also - for help writing your Dockerfile, reference the official documentation for commands here.</p>"},{"location":"05_basic-commands/#running-a-container","title":"Running a container","text":"<p>To create and start a container from an image, run:</p> <pre><code>docker run -it --name &lt;your-container&gt; &lt;your-image-name&gt;\n</code></pre> <ul> <li><code>-it</code>: Attaches an interactive terminal.</li> <li><code>--name &lt;your-container&gt;</code>: Assigns a name to the container.</li> <li><code>&lt;your-image-name&gt;</code>: Refers to the image built earlier. To run container in the background:</li> </ul> <pre><code>docker run -d --name &lt;your-container&gt; &lt;my-image-name&gt;\n</code></pre> <p>To map a port from your host machine to the container, such as host port 8080 to container port 80:</p> <pre><code>docker run -d -p 8080:80 &lt;your-image-name&gt;\n</code></pre>"},{"location":"05_basic-commands/#inspecting-containers","title":"Inspecting Containers","text":"<ul> <li>List running containers:</li> </ul> <pre><code>docker ps\n</code></pre> <ul> <li>List all containers, including stopped ones:</li> </ul> <pre><code>docker ps -a\n</code></pre> <ul> <li>View container logs:</li> </ul> <pre><code>docker logs &lt;your-container&gt;\n</code></pre> <ul> <li>Inspect low-level configuration and state:</li> </ul> <pre><code>docker inspect &lt;your-container&gt;\n</code></pre> <ul> <li>Check real-time resource usage, such as CPU and memory:</li> </ul> <pre><code>docker stats\n</code></pre>"},{"location":"05_basic-commands/#managing-containers","title":"Managing Containers:","text":"<ul> <li>Stop a running container:</li> </ul> <pre><code>docker stop &lt;your-container&gt;\n</code></pre> <ul> <li>Start a stopped container:</li> </ul> <pre><code>docker start &lt;your-container&gt;\n</code></pre> <ul> <li>Restart a container:</li> </ul> <pre><code>docker restart &lt;your-container&gt;\n</code></pre> <ul> <li>Remove a stopped container:</li> </ul> <pre><code>docker rm &lt;your-container&gt;\n</code></pre> <ul> <li>Remove an image:</li> </ul> <pre><code>docker rmi &lt;your-image-name&gt;\n</code></pre>"},{"location":"05_basic-commands/#cleanup-tips","title":"Cleanup Tips","text":"<ul> <li>Remove all stopped containers:</li> </ul> <pre><code>docker container prune\n</code></pre> <ul> <li>Remove unused images:</li> </ul> <pre><code>docker image prune\n</code></pre> <ul> <li>Remove all unused containers, networks, and images:</li> </ul> <pre><code>docker system prune\n</code></pre> <p>Now that you know how to build, run, and manage containers, we can continue to section 6 to show how Docker can simplify development and deployment workflows.</p>"},{"location":"06_examples/","title":"Docker in Practice","text":""},{"location":"06_examples/#example-1-local-development-environment-in-seconds","title":"Example 1: Local Development Environment in Seconds","text":"<p>Without Docker: A developer needs to manually install Python 3.11, PostgreSQL, and Redis, while ensuring all are compatible. Team members might be using slightly different versions, leading to issues where the program only works on some people's machines.</p> <p>With Docker: You can instead create a <code>docker-compose.yml</code> file.</p> <pre><code># docker-compose.yml\nversion: '3'\nservices:\n  web:\n    image: python:3.11\n    volumes:\n      - .:/app\n    working_dir: /app\n    command: python app.py\n  db:\n    image: postgres:15\n    environment:\n      POSTGRES_USER: dev\n      POSTGRES_PASSWORD: secret\n  redis:\n    image: redis:alpine\n</code></pre> <p>Now anyone can spin up the full environment with a single command:</p> <pre><code>docker compose up\n</code></pre> <p>Benefits: * No need to install dependencies locally. * Identical environments across all machines/ * Easy teardown and reset of dev environment.</p>"},{"location":"06_examples/#example-2-portable-web-application-deployment","title":"Example 2: Portable Web Application Deployment","text":"<p>Without Docker: You package a Node.js app, deploy it to a virtual machine, install Node manually, manage system dependencies, worry about OS-specific bugs. With Docker: Create a <code>Dockerfile</code> for your app:</p> <pre><code>FROM node:20-alpine\nWORKDIR /app\nCOPY . .\nRUN npm install\nCMD [\"node\", \"index.js\"]\n</code></pre> <p>Build and push the image to Docker Hub or your registry:</p> <pre><code>docker build -t username/my-node-app .\ndocker push username/my-node-app\n</code></pre> <p>Then deploy on any server (including cloud):</p> <pre><code>docker run -d -p 80:3000 username/my-node-app\n</code></pre> <p>Benefits: * Your app runs the same everywhere: dev, staging, and production. * No need to manage OS-level software * One command deployment on any machine with Docker installed.</p>"},{"location":"06_examples/#example-3-testing-in-clean-disposable-environments","title":"Example 3: Testing in Clean, Disposable Environments","text":"<p>Want to test your app against three different versions of a database?</p> <pre><code>docker run --rm -d --name pg12 postgres:12\ndocker run --rm -d --name pg13 postgres:13\ndocker run --rm -d --name pg15 postgres:15\n</code></pre> <p>Connect your app to each one in turn to verify compatibility without needing to install anything on your machine or spin up separate VMs.</p> <p>Benefits: * Fully isolated test environments. * No polluting your system with conflicting installs. * Test against multiple OS or service versions quickly.</p>"},{"location":"06_examples/#example-4-cicd-integration","title":"Example 4: CI/CD Integration","text":"<p>In CI pipelines (GitHub Actions, GitLab CI, etc.), you can define Docker-based test environments:</p> <pre><code># .github/workflows/test.yml\njobs:\n  test:\n    runs-on: ubuntu-latest\n    services:\n      postgres:\n        image: postgres:15\n        ports:\n          - 5432:5432\n    steps:\n      - uses: actions/checkout@v2\n      - name: Run tests in Docker\n        run: docker build . &amp;&amp; docker run my-app test\n</code></pre> <p>Benefits: * Reliable and reproducible test environments. * Test builds that exactly mirror production. * Reduced setp complexity in CI scripts.</p>"}]}